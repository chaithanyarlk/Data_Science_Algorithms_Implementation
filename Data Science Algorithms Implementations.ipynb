{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionGradient():\n",
    "    def __init__ (self,learning = 0.001,iterations = 5000):\n",
    "        self.learning = learning\n",
    "        self.iterations = iterations\n",
    "    def initialize_weights(self,X):\n",
    "        #print(\"Initializing Weights\",(X.shape)[1])\n",
    "        self.weights = np.zeros((X.shape)[1])\n",
    "    def sigmoid(self,z):\n",
    "        #print(\"Entered Sigmoid Function\")\n",
    "        return (1/(1+np.exp(-z)))\n",
    "    def logLoss(self,X,y):\n",
    "        #print(\"LogLoss function is entered!\")\n",
    "        return ((-1/len(y))*(y*np.log(self.sigmoid(np.dot(X,self.weights)))+(1-y)*np.log(1-self.sigmoid(np.dot(X,self.weights)))).sum())\n",
    "    def gradientDescent(self,X,y):\n",
    "        return (np.dot(X.T,(y-self.sigmoid(np.dot(X,self.weights)))))\n",
    "    def fit(self,X,y):\n",
    "        self.initialize_weights(X)\n",
    "        for i in range(0,self.iterations):\n",
    "            self.weights = self.weights + self.learning * self.gradientDescent(X,y)\n",
    "        print(\"Finally the weights\",self.weights)\n",
    "    def predict(self,X):\n",
    "        y_predict = []\n",
    "        for i in X:\n",
    "            y_predict.append(self.sigmoid(np.dot(self.weights,i)))\n",
    "        return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "number_of_points = 8000\n",
    "means = [[-1,-1],[0.1,2.8]]\n",
    "cov = -0.3\n",
    "covariances = [[[1,cov],[cov,1]],[[1,cov],[cov,1]]] \n",
    "a = np.random.multivariate_normal(means[0],covariances[0],number_of_points)\n",
    "b = np.random.multivariate_normal(means[1],covariances[1],number_of_points)\n",
    "X = np.array([[0.28,0.98,0.94,0.15],[0.33,0.57,0.58,0.04],[0.23,0.96,0.77,0.97]])\n",
    "X = np.hstack((np.ones((X.shape[0],1)),X)) # adding column of ones (biases)\n",
    "y = np.array([1,2,3])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally the weights [15.16536055  3.99809932 12.5694872  10.70820148  9.96678229]\n"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegressionGradient()\n",
    "reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] >= 0.5:\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "y_clf = clf.predict(X_test)\n",
    "accuracy_score(y_test,y_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Both Matrix and Gradient Descent Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Way (Suffers when features are dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[2016],[2017],[2018],[2019],[2020]])\n",
    "y = np.array([12,19,29,37,45])\n",
    "X = np.hstack((np.ones((X.shape[0],1)),X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 2.016e+03],\n",
       "       [1.000e+00, 2.017e+03],\n",
       "       [1.000e+00, 2.018e+03],\n",
       "       [1.000e+00, 2.019e+03],\n",
       "       [1.000e+00, 2.020e+03]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.072326e+05, -2.018000e+02],\n",
       "       [-2.018000e+02,  1.000000e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv(np.dot(X.transpose(),X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 19, 29, 37, 45])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.dot(np.dot(inv(np.dot(X.transpose(),X)),X.transpose()),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.69228e+04,  8.40000e+00])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.60000000553919"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(theta.transpose(),np.array([1,2021]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__ (self,learning = 0.001,iterations = 5000):\n",
    "        self.learning = learning\n",
    "        self.iterations = iterations\n",
    "    def initweights(self,X):\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "    def gradientDescent (self,X,y):\n",
    "        return X.T.dot(X.dot(self.theta) - y)/(len(y))\n",
    "    def costFunction(self,X,y):\n",
    "        m = len(y)\n",
    "        J = np.sum((X.dot(self.theta)-y)**2)/2/m\n",
    "        return J\n",
    "    def fit (self,X,y):\n",
    "        self.initweights(X)\n",
    "        for i in range(self.iterations):\n",
    "            self.theta = self.theta - self.learning*self.gradientDescent(X,y)\n",
    "        print(\"Final Theta values\",self.theta)\n",
    "        print(\"Final cost function\",self.costFunction(X,y))\n",
    "    def predict (self,X):\n",
    "        return np.dot(self.theta.transpose(),X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in subtract\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Theta values [nan]\n",
      "Final cost function nan\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression(learning = 0.0001,iterations = 100000)\n",
    "reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.828517989333076"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(np.array([1,3,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =[[1,3],[2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.   1.5]\n",
      " [ 1.  -0.5]]\n",
      "[[-2.   1.5]\n",
      " [ 1.  -0.5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Apinv = np.linalg.pinv(A)\n",
    "print(Apinv)#use this when inverse is not possible\n",
    "Ainv = np.linalg.inv(A)\n",
    "print(Ainv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = [7,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n"
     ]
    }
   ],
   "source": [
    "A =[[1,3],[2,4]]\n",
    "B = [7,10]\n",
    "import numpy as np\n",
    "Ainv = np.linalg.inv(A)\n",
    "print(Ainv)\n",
    "X = np.dot(Ainv,B)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =[[1,3],[2,4]]\n",
    "B = [7,10]\n",
    "import numpy as np\n",
    "Apinv = np.linalg.pinv(A)\n",
    "print(Apinv)#use this when inverse is not possible\n",
    "X = np.dot(Apinv,B)#When inverse of A is not possible\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNB_own(object):\n",
    "  def __init__(self,alpha):\n",
    "    self.alpha = alpha # alpha is just used for smoothening here\n",
    "  def fit(self,X,y):\n",
    "    seperated = [[x for x, t in zip(X, y) if t == c] for c in np.unique(y)] # Extracting the rows of each class as a matrix here\n",
    "    count_sample = (X.shape)[0] # Getting total rows present\n",
    "    self.class_log_prior_ = [np.log(len(i) / count_sample) for i in seperated] # Calculating the class prior probavilties and applying natural log over it\n",
    "    count = np.array([np.array(i).sum(axis=0) for i in seperated]) + self.alpha # Counting occurence of each word in each class\n",
    "    self.feature_log_prob_ = np.log(count / count.sum(axis=1)[np.newaxis].T) # Calculating likelihood probabilities\n",
    "  def predict_log_proba(self, X):\n",
    "    return [(self.feature_log_prob_ * x).sum(axis=1) + self.class_log_prior_ for x in X] # Simply caluclating posterior probabilities for each class of the word and returning the array of the values seperated for each class\n",
    "  def predict(self, X):\n",
    "    return np.argmax(self.predict_log_proba(X), axis=1) # Simply picking the column which has highest value for each word of the given array as test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m<n\n",
    "A = \n",
    "B =\n",
    "print(np.linalg.inv(np.dot(A,A.transpose())))\n",
    "X = np.dot(np.dot(A.transpose(),np.linalg.inv(np.dot(A,A.transpose()))),B)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
